{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOslpmw0dBKhTHksBeoR0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mTwR0/Transcriber/blob/main/Audio_transcriber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "first, take audio, check for holds or silence for more than x seconds.\n",
        "\n",
        "cut that into other audio segments or multiple files"
      ],
      "metadata": {
        "id": "524zmfL6-p88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wDXFNX6tp2l"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets librosa pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your audio file\n",
        "call_file = r'/content/drive/MyDrive/Colab Notebooks/test_call.wav'\n",
        "\n",
        "# Verify the file exists\n",
        "print(\"File exists:\", os.path.exists(call_file))\n"
      ],
      "metadata": {
        "id": "x3BFLM-ougd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment, silence\n",
        "\n",
        "# Load the audio file\n",
        "audio = AudioSegment.from_file(call_file)\n",
        "\n",
        "# Detect silent segments\n",
        "silence_threshold = -50  # Silence threshold in dBFS\n",
        "min_silence_length = 5000  # Minimum silence length in ms\n",
        "silent_ranges = silence.detect_silence(audio, min_silence_len=min_silence_length, silence_thresh=silence_threshold)\n",
        "\n",
        "# Convert silent ranges to seconds for readability\n",
        "silent_ranges = [(start / 1000, end / 1000) for start, end in silent_ranges]\n",
        "print(\"Silent ranges (start, end in seconds):\", silent_ranges)\n",
        "\n",
        "# Remove silence and combine non-silent parts\n",
        "non_silent_audio = silence.split_on_silence(\n",
        "    audio,\n",
        "    min_silence_len=min_silence_length,\n",
        "    silence_thresh=silence_threshold,\n",
        "    keep_silence=200  # Keep small silence padding\n",
        ")\n",
        "\n",
        "# Combine the non-silent chunks into one audio segment\n",
        "processed_audio = sum(non_silent_audio)\n",
        "\n",
        "# Save the processed audio to a new file\n",
        "processed_audio_path = r'/content/drive/MyDrive/Colab Notebooks/processed_audio.wav'\n",
        "processed_audio.export(processed_audio_path, format=\"wav\")\n",
        "print(f\"Processed audio saved to {processed_audio_path}\")\n"
      ],
      "metadata": {
        "id": "Vv2tv_8C_-S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in My Drive to verify your file is there\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "print(os.path.exists(processed_audio_path))\n"
      ],
      "metadata": {
        "id": "ffTersll3K1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "transcriber = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-large-v3-turbo\",\n",
        "    return_timestamps=True\n",
        ")\n",
        "\n",
        "# Transcribe the processed audio\n",
        "result = transcriber(processed_audio_path)\n",
        "\n",
        "# Print the transcription\n",
        "print(\"Transcription:\", result[\"text\"])\n"
      ],
      "metadata": {
        "id": "2mDyU1nr1UWC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}